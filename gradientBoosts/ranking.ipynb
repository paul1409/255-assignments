{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRanker, Pool\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from xgboost import XGBRanker\n",
    "from catboost import CatBoostRanker\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=5000, \n",
    "    n_features= 10, \n",
    "    n_classes=3, \n",
    "    n_clusters_per_class=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRanker(max_depth=5, learning_rate=.01, n_estimators=2000, n_jobs=-1, colsample_bytree=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "group or qid is required for ranking task",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6608/649140684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, group, qid, sample_weight, base_margin, eval_set, eval_group, eval_qid, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1702\u001b[0m         \u001b[1;31m# check if group information is provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mqid\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1704\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"group or qid is required for ranking task\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: group or qid is required for ranking task"
     ]
    }
   ],
   "source": [
    "xgbr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_train = [X_train.shape[0]]\n",
    "query_val = [X_val.shape[0]]\n",
    "query_test = [X_test.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbr = LGBMRanker(device=\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\savio\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@5: 0.773893\tvalid_0's ndcg@10: 0.891066\tvalid_0's ndcg@20: 0.901055\n",
      "[2]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[3]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[4]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[5]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[6]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[7]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[8]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[9]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[10]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[11]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[12]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[13]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[14]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[15]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[16]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 0.998167\tvalid_0's ndcg@20: 0.998335\n",
      "[17]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[18]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[19]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[20]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[21]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[22]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[23]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[24]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[25]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[26]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[27]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[28]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[29]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[30]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[31]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[32]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[33]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[34]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[35]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[36]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[37]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[38]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[39]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[40]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[41]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[42]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[43]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[44]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[45]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[46]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[47]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[48]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[49]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[50]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[51]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n",
      "[52]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\tvalid_0's ndcg@20: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(device='gpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbr.fit(X_train, y_train, group=query_train,\n",
    "        eval_set=[(X_val, y_val)], eval_group=[query_val],\n",
    "        eval_at=[5, 10, 20], early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.datasets import msrank_10k\n",
    "train_df, test_df = msrank_10k()\n",
    "\n",
    "X_train = train_df.drop([0, 1], axis=1).values\n",
    "y_train = train_df[0].values\n",
    "queries_train = train_df[1].values\n",
    "\n",
    "X_test = test_df.drop([0, 1], axis=1).values\n",
    "y_test = test_df[0].values\n",
    "queries_test = test_df[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "num_documents = X_train.shape[0]\n",
    "print(num_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(2.0, 1326), (0.0, 5481), (1.0, 3000), (3.0, 142), (4.0, 51)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_relevance = np.max(y_train)\n",
    "y_train /= max_relevance\n",
    "y_test /= max_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_queries = np.unique(queries_train).shape[0]\n",
    "num_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=queries_train\n",
    ")\n",
    "\n",
    "test = Pool(\n",
    "    data=X_test,\n",
    "    label=y_test,\n",
    "    group_id=queries_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './msrank'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "train_file = os.path.join(data_dir, 'train.csv')\n",
    "test_file = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "train_df.to_csv(train_file, index=False, header=False)\n",
    "test_df.to_csv(test_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_file = os.path.join(data_dir, 'dataset.cd')\n",
    "with open(description_file, 'w') as f:\n",
    "    f.write('0\\tLabel\\n')\n",
    "    f.write('1\\tQueryId\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.Pool at 0x229a8bee7c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pool(data=train_file, column_description=description_file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = {\n",
    "    'iterations': 2000,\n",
    "    'custom_metric': ['NDCG', 'PFound', 'AverageGain:top=10'],\n",
    "    'verbose': False,\n",
    "    'random_seed': 0,\n",
    "}\n",
    "\n",
    "parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(loss_function, additional_params=None, train_pool=train, test_pool=test):\n",
    "    parameters = deepcopy(default_parameters)\n",
    "    parameters['loss_function'] = loss_function\n",
    "    parameters['train_dir'] = loss_function\n",
    "    \n",
    "    if additional_params is not None:\n",
    "        parameters.update(additional_params)\n",
    "        \n",
    "    model = CatBoostRanker(**parameters)\n",
    "    model.fit(train_pool, eval_set=test_pool, plot=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\savio\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\catboost\\core.py:5806: RuntimeWarning: Regression loss ('RMSE') ignores an important ranking parameter 'group_id'\n",
      "  warnings.warn(\"Regression loss ('{}') ignores an important ranking parameter 'group_id'\".format(loss_function), RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e18bd33383349e99bb5c797ee2b191f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = fit_model('RMSE', {'custom_metric': ['PrecisionAt:top=10', 'RecallAt:top=10', 'MAP:top=10']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b83983607b14c329cf1e2a3cb941c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x2297f773070>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_weights(queries):\n",
    "    query_set = np.unique(queries)\n",
    "    query_weights = np.random.uniform(size=query_set.shape[0])\n",
    "    weights = np.zeros(shape=queries.shape)\n",
    "    \n",
    "    for i, query_id in enumerate(query_set):\n",
    "        weights[queries == query_id] = query_weights[i]\n",
    "    \n",
    "    return weights\n",
    "    \n",
    "\n",
    "train_with_weights = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_weight=create_weights(queries_train),\n",
    "    group_id=queries_train\n",
    ")\n",
    "\n",
    "test_with_weights = Pool(\n",
    "    data=X_test,\n",
    "    label=y_test,\n",
    "    group_weight=create_weights(queries_test),\n",
    "    group_id=queries_test\n",
    ")\n",
    "\n",
    "fit_model(\n",
    "    'RMSE', \n",
    "    additional_params={'train_dir': 'RMSE_weigths'}, \n",
    "    train_pool=train_with_weights,\n",
    "    test_pool=test_with_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_documents(labels, queries):\n",
    "    query_set = np.unique(queries)\n",
    "    num_queries = query_set.shape[0]\n",
    "    by_query_arg_max = {query: -1 for query in query_set}\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        best_idx = by_query_arg_max[query]\n",
    "        if best_idx == -1 or labels[best_idx] < labels[i]:\n",
    "            by_query_arg_max[query] = i\n",
    "    \n",
    "    binary_best_docs = np.zeros(shape=labels.shape)\n",
    "    for arg_max in by_query_arg_max.values():\n",
    "        binary_best_docs[arg_max] = 1.\n",
    "        \n",
    "    return binary_best_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bd2dd5c6b0477ebc8f3104462cae9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x229af5a3fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_docs_train = get_best_documents(y_train, queries_train)\n",
    "best_docs_test = get_best_documents(y_test, queries_test)\n",
    "\n",
    "train_with_weights = Pool(\n",
    "    data=X_train,\n",
    "    label=best_docs_train,\n",
    "    group_id=queries_train,\n",
    "    group_weight=create_weights(queries_train)\n",
    ")\n",
    "\n",
    "test_with_weights = Pool(\n",
    "    data=X_test,\n",
    "    label=best_docs_test,\n",
    "    group_id=queries_test,\n",
    "    group_weight=create_weights(queries_test)\n",
    ")\n",
    "\n",
    "fit_model(\n",
    "    'QuerySoftMax',\n",
    "    additional_params={'custom_metric': 'AverageGain:top=1'},\n",
    "    train_pool=train_with_weights,\n",
    "    test_pool=test_with_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77e89ddf8f64327a197708f88aba29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x229af5a35e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model('QueryRMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455beeaeba7248c79355447b78fb53c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x229af5a3730>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model('PairLogit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_groups(file_name):\n",
    "    groups = {}\n",
    "    group_ids = []\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        for doc_id, line in enumerate(f):\n",
    "            line = line.split(',')[:2]\n",
    "            \n",
    "            label, query_id = float(line[0]), int(line[1])\n",
    "            if query_id not in groups:\n",
    "                groups[query_id] = []\n",
    "            groups[query_id].append((doc_id, label))\n",
    "\n",
    "            group_ids.append(query_id)\n",
    "\n",
    "    return groups, group_ids\n",
    "            \n",
    "train_groups, train_group_ids = read_groups(train_file)\n",
    "assert num_queries == len(train_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "for group in train_groups.values():\n",
    "    for i in range(len(group)):\n",
    "        for j in range(i, len(group)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            doc_i, relevance_i = group[i]\n",
    "            doc_j, relevance_j = group[j]\n",
    "            if relevance_i < relevance_j:\n",
    "                pairs.append((doc_j, doc_i))\n",
    "            else:\n",
    "                pairs.append((doc_i, doc_j))\n",
    "                \n",
    "pairs_file = os.path.join(data_dir, 'pairs.csv')\n",
    "\n",
    "with open(pairs_file, 'w') as f:\n",
    "    for pair in pairs:\n",
    "        f.write(str(pair[0]) + '\\t' + str(pair[1]) + '\\t1\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = Pool(data=X_train, label=y_train, group_id=train_group_ids, pairs=pairs)\n",
    "pool2 = Pool(data=train_file, column_description=description_file, pairs=pairs_file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935e0ac2a77d4dcb971f1676fa9405b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x229af62d940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model('PairLogitPairwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ff47fbc6024881bc49e6b232c7f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x229af62dcd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model('YetiRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5bd98fe47c40278b87723616a8b948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x229af62d460>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model('YetiRankPairwise')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e4631f8abf22b6e3bad75ef6fc74e8156bc6d7eda16a6da5468122f1c7f4a75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
